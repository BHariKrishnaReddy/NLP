{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgtLi2l92X0V",
        "outputId": "a91cb40f-0efa-4351-edac-cdf1eb38c4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Dropout\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To avoid encoding errors\n",
        "import chardet\n",
        "with open('/content/train.csv', 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(100000))\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f8Xv5jI56Ko",
        "outputId": "f1e8853b-6523-40dd-d43f-a07c949bf69d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid **field larger than field limit (131072)** issue we need increase `field_size_limit` and according there might be cases where few bad lines might be appended at end so handle them use `error_bad_lines=False`"
      ],
      "metadata": {
        "id": "ERFJLevB7YhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "maxInt = sys.maxsize\n",
        "\n",
        "while True:\n",
        "    # decrease the maxInt value by factor 10 \n",
        "    # as long as the OverflowError occurs.\n",
        "    try:\n",
        "        csv.field_size_limit(maxInt)\n",
        "        break\n",
        "    except OverflowError:\n",
        "        maxInt = int(maxInt/10)"
      ],
      "metadata": {
        "id": "6RoXlmRQ4OL-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/train.csv\",engine=\"python\",encoding='utf-8',error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLvlQIJS60Dw",
        "outputId": "0c18055e-a4bc-41bf-ba92-0d9fa51af29f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "Skipping line 7354: unexpected end of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('label',axis=1)\n",
        "Y = df['label']"
      ],
      "metadata": {
        "id": "UZViigRU73EP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_size = 5000 #no.of unique vocabulary words you want store for this model"
      ],
      "metadata": {
        "id": "QLeoDLc88ODk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding with `one_hot`"
      ],
      "metadata": {
        "id": "OhXITph68zAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=X.copy()\n",
        "messages.reset_index(inplace=True)\n",
        "\n",
        "### Dataset Preprocessing\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "    review = re.sub(\"[^a-zA-Z]\", \" \", str(messages['title'][i]))\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "onehot_repr=[one_hot(words,voc_size)for words in corpus] "
      ],
      "metadata": {
        "id": "Pq_V_GjM8jtF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_length=20 #it will make the all inputs to be equal before passing to NN\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "\n",
        "## Creating model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Jcx0GZT59e3r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-7slzhAJZxv",
        "outputId": "afdb61e4-603c-4161-bdc1-448f17d61ba7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               56400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,501\n",
            "Trainable params: 256,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(Y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)\n",
        "### Model Training\n",
        "### Finally Training\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tD5jdhG-9bh",
        "outputId": "0cb5caad-303b-4723-863f-3d91734e5b3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "77/77 [==============================] - 12s 98ms/step - loss: 0.4928 - accuracy: 0.7488 - val_loss: 0.3491 - val_accuracy: 0.8492\n",
            "Epoch 2/10\n",
            "77/77 [==============================] - 4s 53ms/step - loss: 0.1783 - accuracy: 0.9332 - val_loss: 0.2008 - val_accuracy: 0.9147\n",
            "Epoch 3/10\n",
            "77/77 [==============================] - 2s 27ms/step - loss: 0.0957 - accuracy: 0.9657 - val_loss: 0.2148 - val_accuracy: 0.9126\n",
            "Epoch 4/10\n",
            "77/77 [==============================] - 2s 27ms/step - loss: 0.0489 - accuracy: 0.9842 - val_loss: 0.2664 - val_accuracy: 0.9147\n",
            "Epoch 5/10\n",
            "77/77 [==============================] - 2s 26ms/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.2882 - val_accuracy: 0.9126\n",
            "Epoch 6/10\n",
            "77/77 [==============================] - 2s 25ms/step - loss: 0.0099 - accuracy: 0.9986 - val_loss: 0.3781 - val_accuracy: 0.9073\n",
            "Epoch 7/10\n",
            "77/77 [==============================] - 2s 28ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.3782 - val_accuracy: 0.9089\n",
            "Epoch 8/10\n",
            "77/77 [==============================] - 2s 27ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.4214 - val_accuracy: 0.9081\n",
            "Epoch 9/10\n",
            "77/77 [==============================] - 2s 27ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4331 - val_accuracy: 0.9131\n",
            "Epoch 10/10\n",
            "77/77 [==============================] - 2s 27ms/step - loss: 5.9606e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f617cb387f0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "v2DQcJd6AfID"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUOspKMrJcVT",
        "outputId": "bc00a992-36ce-446b-fed6-bdc7fa907de1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 40)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,501\n",
            "Trainable params: 256,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}