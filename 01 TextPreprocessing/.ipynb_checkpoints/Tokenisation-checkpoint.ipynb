{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7d6863",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is the process of breaking down text into smaller units, called tokens. Tokens are typically words, phrases, or sentences that can be further processed for various natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8a82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of 'de Finibus Bonorum et Malorum' (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, 'Lorem ipsum dolor sit amet..', comes from a line in section 1.10.32.The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from 'de Finibus Bonorum et Malorum' by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd49f21",
   "metadata": {},
   "source": [
    "#### Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9dbb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harikrishnareddy/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem', 'Ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.', 'Lorem', 'Ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', '1500s', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.', 'It', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.', 'It', 'was', 'popularised', 'in', 'the', '1960s', 'with', 'the', 'release', 'of', 'Letraset', 'sheets', 'containing', 'Lorem', 'Ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'Aldus', 'PageMaker', 'including', 'versions', 'of', 'Lorem', 'Ipsum.Contrary', 'to', 'popular', 'belief', ',', 'Lorem', 'Ipsum', 'is', 'not', 'simply', 'random', 'text', '.', 'It', 'has', 'roots', 'in', 'a', 'piece', 'of', 'classical', 'Latin', 'literature', 'from', '45', 'BC', ',', 'making', 'it', 'over', '2000', 'years', 'old', '.', 'Richard', 'McClintock', ',', 'a', 'Latin', 'professor', 'at', 'Hampden-Sydney', 'College', 'in', 'Virginia', ',', 'looked', 'up', 'one', 'of', 'the', 'more', 'obscure', 'Latin', 'words', ',', 'consectetur', ',', 'from', 'a', 'Lorem', 'Ipsum', 'passage', ',', 'and', 'going', 'through', 'the', 'cites', 'of', 'the', 'word', 'in', 'classical', 'literature', ',', 'discovered', 'the', 'undoubtable', 'source', '.', 'Lorem', 'Ipsum', 'comes', 'from', 'sections', '1.10.32', 'and', '1.10.33', 'of', \"'de\", 'Finibus', 'Bonorum', 'et', 'Malorum', \"'\", '(', 'The', 'Extremes', 'of', 'Good', 'and', 'Evil', ')', 'by', 'Cicero', ',', 'written', 'in', '45', 'BC', '.', 'This', 'book', 'is', 'a', 'treatise', 'on', 'the', 'theory', 'of', 'ethics', ',', 'very', 'popular', 'during', 'the', 'Renaissance', '.', 'The', 'first', 'line', 'of', 'Lorem', 'Ipsum', ',', \"'Lorem\", 'ipsum', 'dolor', 'sit', 'amet', '..', \"'\", ',', 'comes', 'from', 'a', 'line', 'in', 'section', '1.10.32.The', 'standard', 'chunk', 'of', 'Lorem', 'Ipsum', 'used', 'since', 'the', '1500s', 'is', 'reproduced', 'below', 'for', 'those', 'interested', '.', 'Sections', '1.10.32', 'and', '1.10.33', 'from', \"'de\", 'Finibus', 'Bonorum', 'et', 'Malorum', \"'\", 'by', 'Cicero', 'are', 'also', 'reproduced', 'in', 'their', 'exact', 'original', 'form', ',', 'accompanied', 'by', 'English', 'versions', 'from', 'the', '1914', 'translation', 'by', 'H.', 'Rackham', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Tokenize text into words\n",
    "words = word_tokenize(para)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f14447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.', \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\", 'It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.', 'It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.Contrary to popular belief, Lorem Ipsum is not simply random text.', 'It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old.', 'Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source.', \"Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of 'de Finibus Bonorum et Malorum' (The Extremes of Good and Evil) by Cicero, written in 45 BC.\", 'This book is a treatise on the theory of ethics, very popular during the Renaissance.', \"The first line of Lorem Ipsum, 'Lorem ipsum dolor sit amet..', comes from a line in section 1.10.32.The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested.\", \"Sections 1.10.32 and 1.10.33 from 'de Finibus Bonorum et Malorum' by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\"]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text into sentences\n",
    "sentences = sent_tokenize(para)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2407c4",
   "metadata": {},
   "source": [
    "#### Tokenization using SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") # a small English language model that has been trained on a large corpus of text data\n",
    "\n",
    "# Tokenize text\n",
    "doc = nlp(para)\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea19b46",
   "metadata": {},
   "source": [
    "#### Tokenization using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0eda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Tokenize text\n",
    "sktokens = vectorizer.build_tokenizer()(para)\n",
    "print(sktokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e0e19",
   "metadata": {},
   "source": [
    "#### Tokenization using KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Create a tokenizer instance\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the text data\n",
    "tokenizer.fit_on_texts(para)\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.texts_to_sequences([para])[0]\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23862c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
